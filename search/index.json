[{"content":"nginx 中使用 upstream 标识转发的上游服务的服务列表，如下：\n1 2 3 4 upstream example { server 192.168.21.1:8080; server 192.168.21.2:8080; } 默认使用的负载均衡策略是轮询，当服务节点的承载能力不一样时，nginx 可以支持使用 weight 属性确定节点的负载权重，如下所示：\n1 2 3 4 5 upstream cluster { server 192.168.21.1:8080 weight=2; server 192.168.21.2:8080 weight=1; server 192.168.21.3:8080 weight=3; } 按照常规的思路，每 6 个请求一轮回，前 2 次转到 192.168.21.1:8080 ，第 3 次转到 192.168.21.2:8080 ，最后 3 次转到 192.168.21.3:8080 即可\n但是这样的加权轮询算法有一个问题，就是不够“平滑”，假设权重的列表是类似 [10, 2, 1] 这种形式，那么前十次请求将会全部转发到第一个节点，要是能把后面两个节点穿插到这些请求中就好了\nnginx 就使用一种“平滑”的加权轮询算法实现了这一特点，在上面的例子中，我们假设\n192.168.21.1:8080：A 192.168.21.2:8080：B 192.168.21.3:8080：C 对于普通的加权轮询算法，其 6 次请求的负载列表如下：\n[A, A, B, C, C, C]\n而使用 nginx 的加权轮询算法，得到的负载列表则如下所示：\n[C, A, B, C, A, C]\n可以看到 nginx 的加权轮询算法得到的负载列表更加的均匀，有效地将所有节点根据权重均匀的分摊开来，下面让我们看看 nginx 是如何实现的\n原理 参数 在 nginx 的加权轮询算法中，有 3 个重要的参数：\nweight：配置文件中指定的权重，这个值是固定不变的 effective_weight：节点的有效权重，其初始值是 weight。在释放后端的过程中，如果与节点的通信发生错误，就减小 effective_weight；在后续请求中，选取节点时再逐步增加 effective_weight 直至恢复到 weight。这个参数的作用主要就是当节点发生错误时，减少其权重，减少分摊到此节点的请求 current_weight：节点当前的权重，初始值为 0，会在选取过程中动态调整。选取过程中，遍历所有节点，使得每个节点的 current_weight 等于原 current_weight 加上其 effective_weight，同时累加所有节点的 effective_weight 为 total，然后选取 current_weight 最大的节点作为最终的选中节点，并将其 current_weight 等于原 current_weight 减去 total（没有被选中的节点无需减去 total） 举个栗子 这么说可能有些抽象，用一个列表来描述可能更加形象一些，还是上面 [2, 1, 3] 的权重列表，依旧以 [A, B, C] 代替节点，其负载过程如下所示：\n请求序列 选定之前的 current_weight 列表 选中节点 选定之后的 current_weight 列表 1 [2, 1, 3] C [2, 1, -3] 2 [4, 2, 0] A [-2, 2, 0] 3 [0, 3, 3] B [0, -3, 3] 4 [2, -2, 6] C [2, -2, 0] 5 [4, -1, 3] A [-2, -1, 3] 6 [0, 0, 6] C [0, 0, 0] 7 [2, 1, 3] C [2, 1, -3] 可以看到，其前 6 次负载列表为：[C, A, B, C, A, C]，且在第 6 次请求后，current_weight 列表恢复到了初始的 [0, 0, 0] 状态，也就是说其负载列表将会一直以 [C, A, B, C, A, C] 的形式循环下去\n实现 下面以 Java 为例，实现这一负载均衡算法\n节点类 首先定义一个简单的节点类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 public class Instance implements Serializable { @Serial private static final long serialVersionUID = 535926252786888744L; private String host; private Integer port; private Integer weight; private Integer effectiveWeight; private Integer currentWeight; public Instance() { } public Instance(String host, Integer port, Integer weight) { this.host = host; this.port = port; this.weight = weight; this.effectiveWeight = weight; this.currentWeight = 0; } public String getHost() { return host; } public void setHost(String host) { this.host = host; } public Integer getPort() { return port; } public void setPort(Integer port) { this.port = port; } public Integer getWeight() { return weight; } public void setWeight(Integer weight) { this.weight = weight; } public Integer getEffectiveWeight() { return effectiveWeight; } public void setEffectiveWeight(Integer effectiveWeight) { this.effectiveWeight = effectiveWeight; } public Integer getCurrentWeight() { return currentWeight; } public void setCurrentWeight(Integer currentWeight) { this.currentWeight = currentWeight; } @Override public String toString() { return \u0026#34;Instance{\u0026#34; + \u0026#34;host=\u0026#39;\u0026#34; + host + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, port=\u0026#34; + port + \u0026#34;, weight=\u0026#34; + weight + \u0026#39;}\u0026#39;; } } 这个节点类除了包含最基本的 host、port、weight 属性外，还有两个属性，即 effectiveWeight 和 currentWeight，用来表示节点的有效权重和当前权重\n负载均衡器 接着定义一个 LoadBalancer 接口类：\n1 2 3 public interface LoadBalancer { Instance choose(); } 编写加权轮询负载均衡器实现这个接口：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public class RoundRobinLoadBalancer implements LoadBalancer { private final List\u0026lt;Instance\u0026gt; instances; public RoundRobinLoadBalancer(List\u0026lt;Instance\u0026gt; instances) { this.instances = instances; } @Override public Instance choose() { int total = 0; for (Instance instance : instances) { int effectiveWeight = instance.getEffectiveWeight(); int currentWeight = instance.getCurrentWeight(); currentWeight += effectiveWeight; instance.setCurrentWeight(currentWeight); total += effectiveWeight; } int max = 0; int index = 0; for (int i = 0; i \u0026lt; instances.size(); i++) { int currentWeight = instances.get(i).getCurrentWeight(); if (currentWeight \u0026gt; max) { max = currentWeight; index = i; } } Instance selectedInstance = instances.get(index); int selectedWeight = selectedInstance.getCurrentWeight(); int currentWeight = selectedWeight - total; selectedInstance.setCurrentWeight(currentWeight); return selectedInstance; } } 测试 测试是否运行正确：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class RoundRobinLoadBalancerTest { @Test public void test() { List\u0026lt;Instance\u0026gt; instances = List.of( new Instance(\u0026#34;192.168.21.1\u0026#34;, 8080, 2), new Instance(\u0026#34;192.168.21.2\u0026#34;, 8080, 1), new Instance(\u0026#34;192.168.21.3\u0026#34;, 8080, 3) ); LoadBalancer loadBalancer = new RoundRobinLoadBalancer(instances); List\u0026lt;String\u0026gt; expectedHosts = List.of( \u0026#34;192.168.21.3\u0026#34;, \u0026#34;192.168.21.1\u0026#34;, \u0026#34;192.168.21.2\u0026#34;, \u0026#34;192.168.21.3\u0026#34;, \u0026#34;192.168.21.1\u0026#34;, \u0026#34;192.168.21.3\u0026#34; ); for (int i = 0; i \u0026lt; 18; i++) { Instance instance = loadBalancer.choose(); String actual = instance.getHost(); int index = i % 6; String expected = expectedHosts.get(index); Assertions.assertEquals(expected, actual); } } } 如期运行\nCover from Sergio Zhukov on unsplash\n","date":"2023-07-24T00:00:00Z","image":"https://yameizitd.github.io/p/%E5%B9%B3%E6%BB%91%E7%9A%84%E5%8A%A0%E6%9D%83%E8%BD%AE%E8%AF%A2%E7%AE%97%E6%B3%95/cover_hu3d03a01dcc18bc5be0e67db3d8d209a6_331037_120x120_fill_q75_box_smart1.jpg","permalink":"https://yameizitd.github.io/p/%E5%B9%B3%E6%BB%91%E7%9A%84%E5%8A%A0%E6%9D%83%E8%BD%AE%E8%AF%A2%E7%AE%97%E6%B3%95/","title":"平滑的加权轮询算法"},{"content":"Java 的集合框架主要分为两个部分：Collection 和 Map\nCollection Collection 主要有三个接口：List、Set 和 Queue\nList List 是列表结构，在 Java 中主要有两种常用的实现：ArrayList 和 LinkedList\nArrayList ArrayList 是基于动态数组实现的列表结构，简单来说就是使用数组的每个槽位存储节点，使用一个整型标识元素的数量，每次插入元素时比较元素数量是否超过数组容量，超过则进行扩容\n尾部插入元素的源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 public boolean add(E e) { modCount++; add(e, elementData, size); return true; } private void add(E e, Object[] elementData, int s) { if (s == elementData.length) elementData = grow(); elementData[s] = e; size = s + 1; } 可以看到，当元素数量等于数组容量时，就会进行扩容操作，扩容源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 private Object[] grow() { return grow(size + 1); } private Object[] grow(int minCapacity) { int oldCapacity = elementData.length; if (oldCapacity \u0026gt; 0 || elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { int newCapacity = ArraysSupport.newLength(oldCapacity, minCapacity - oldCapacity, /* minimum growth */ oldCapacity \u0026gt;\u0026gt; 1 /* preferred growth */); return elementData = Arrays.copyOf(elementData, newCapacity); } else { return elementData = new Object[Math.max(DEFAULT_CAPACITY, minCapacity)]; } } // ArraysSupport.java public static int newLength(int oldLength, int minGrowth, int prefGrowth) { // preconditions not checked because of inlining // assert oldLength \u0026gt;= 0 // assert minGrowth \u0026gt; 0 int prefLength = oldLength + Math.max(minGrowth, prefGrowth); // might overflow if (0 \u0026lt; prefLength \u0026amp;\u0026amp; prefLength \u0026lt;= SOFT_MAX_ARRAY_LENGTH) { return prefLength; } else { // put code cold in a separate method return hugeLength(oldLength, minGrowth); } } 简单来说，就是原始数组容量大小 + 原数组容量大小右移一位（即 0.5 倍的原数组容量大小），即原数组容量大小的 1.5 倍 在扩容期间，直接使用 Arrays.copyOf 方法，这最终是调用一个 JNI 方法，源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // Arrays.java public static \u0026lt;T,U\u0026gt; T[] copyOf(U[] original, int newLength, Class\u0026lt;? extends T[]\u0026gt; newType) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) T[] copy = ((Object)newType == (Object)Object[].class) ? (T[]) new Object[newLength] : (T[]) Array.newInstance(newType.getComponentType(), newLength); System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy; } // System.java public static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length); 按索引位置插入元素的代码是类似的，只是需要使用 Arrays.copyOf 将索引位置及以后的元素全部往后移动一个槽位，以空出索引位置的槽位供新元素插入。这也是 ArrayList 非尾部插入效率低下的原因，存在大量的数据拷贝\n删除元素时，就是从头开始遍历，直到找到对应的元素，然后记录下标，最后使用 Arrays.copyOf 将索引位置后面的元素全部前移一个槽位，这样索引位置的元素就等于被删除了。源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public boolean remove(Object o) { final Object[] es = elementData; final int size = this.size; int i = 0; found: { if (o == null) { for (; i \u0026lt; size; i++) if (es[i] == null) break found; } else { for (; i \u0026lt; size; i++) if (o.equals(es[i])) break found; } return false; } fastRemove(es, i); return true; } private void fastRemove(Object[] es, int i) { modCount++; final int newSize; if ((newSize = size - 1) \u0026gt; i) System.arraycopy(es, i + 1, es, i, newSize - i); es[size = newSize] = null; } 所以，ArrayList 的删除操作也是比较低效的，可能存在大量数据的复制拷贝\nArrayList 根据索引位置的查询操作十分高效，因为使用的数组结构，通过索引位置查找元素时，直接返回对应位置的元素即可\n其他一些常用的操作方法也是类似的，大多使用 Arrays.copyOf 方法完成\n综上，ArrayList 的尾插和按索引查找效率很高，但是删除元素和非尾插效率较低\nLinkedList LinkedList 是基于双向链表实现的，其节点的数据结构如下：\n1 2 3 4 5 6 7 8 9 10 11 private static class Node\u0026lt;E\u0026gt; { E item; Node\u0026lt;E\u0026gt; next; Node\u0026lt;E\u0026gt; prev; Node(Node\u0026lt;E\u0026gt; prev, E element, Node\u0026lt;E\u0026gt; next) { this.item = element; this.next = next; this.prev = prev; } } 可以看到，有两个类似指针作用的引用，分别指向前一个节点和后一个节点\n尾插元素时，只需要将元素链接到链表的尾部即可，源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public boolean add(E e) { linkLast(e); return true; } void linkLast(E e) { final Node\u0026lt;E\u0026gt; l = last; final Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++; } 可以看到，在 LinkedList 中，有一个 last 属性，它指向链表的尾部节点，在尾插时，首先根据元素构建新节点（新节点的前驱指针指向之前 last），然后让 last 重新指向新节点（即重新指向尾部节点，因为新节点成为了新的尾部节点），最后再让新节点的前一个节点的后驱指针指向新节点即完成了尾插操作。流程大致如下： 按索引位置插入元素的逻辑与头部类似，稍复杂一步，就是个简单的双向链表中间添加节点的操作，源码如下：\n1 2 3 4 5 6 7 public void add(int index, E element) { checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index)); } 注意这里的 node 方法，这个方法在按索引位置查找元素时也会用到，这是个很有意思的方法，源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Node\u0026lt;E\u0026gt; node(int index) { // assert isElementIndex(index); if (index \u0026lt; (size \u0026gt;\u0026gt; 1)) { Node\u0026lt;E\u0026gt; x = first; for (int i = 0; i \u0026lt; index; i++) x = x.next; return x; } else { Node\u0026lt;E\u0026gt; x = last; for (int i = size - 1; i \u0026gt; index; i--) x = x.prev; return x; } } 可以看到，这里先将当前链表的长度右移一位（即除以 2 ），然后拿索引位置和长度的一半作比较，小于则从链表头部往后找，大于就从链表尾部往前找，这算是一个小小的二分查找优化 找到要插入位置的元素后，就是插入操作了，主要看 linkBefore 方法，源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 void linkBefore(E e, Node\u0026lt;E\u0026gt; succ) { // assert succ != null; final Node\u0026lt;E\u0026gt; pred = succ.prev; final Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++; } 一个标准的双向链表中间插入方法，首先构建新节点，新节点的前驱指针指向索引节点的前一个节点，后驱指针指向索引节点，再将索引节点的前驱指针指向新节点，最后让之前那个索引节点的前节点的后驱指针指向新节点，插入完毕。流程如下： 按索引位置查找元素主要就是利用之前所说的 node 方法，不再赘述\n综上，基于双链表实现的 LinkedList ，其尾插和按索引位置插入删除是相对高效的，但是按索引位置的查找效率较低，因为需要遍历链表来获取元素（其实按索引位置增删也是需要先找到对应位置的节点，但是增删相对 ArrayList 来说，不需要移动大量的元素，只要简单的修改几个引用的指向即可）\n关于 LinkedList 的一些其它小特性 观察 LinkedList 的类声明可以发现，其还实现了 Deque 接口：\n1 2 3 4 public class LinkedList\u0026lt;E\u0026gt; extends AbstractSequentialList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, Deque\u0026lt;E\u0026gt;, Cloneable, java.io.Serializable { Deque 是 java 中的双端队列接口，也就是说 LinkedList 还可以当作队列来使用，从其双向链表的基层来看，确实也是可以作为双端队列的实现\nSet Set 中最常用的是 HashSet\nHashSet HashSet 是基于 HashMap 实现的，其实际是使用 HashMap 的 key 存储元素，而 HashMap 的 key 正好可以保证唯一性，可以参见 HashMap 的具体实现，不再赘述\nQueue Queue 是 java 中的队列接口，队列是一种先进先出的结构，Queue 还有个子接口，就是我们之前说的 Deque ，Deque 是双端队列 Queue 有一个很经典的实现是 PriorityQueue\nPriorityQueue PriorityQueue 是一个优先队列，放入其中的元素会按照顺序摆放好，队头是最小的元素，这里对其原理不做阐述，感兴趣的可以翻看源码\nPriorityQueue 有一个经典的应用场景：TopK 假设有一个无序 int 数组 array ，现在要求获取其前 k 个最大的元素？ 使用 PriorityQueue 解决这个问题将会非常简单：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public int[] getTopK(int[] array, int k) { PriorityQueue\u0026lt;Integer\u0026gt; priorityQueue = new PriorityQueue\u0026lt;\u0026gt;(k); for (int i : array) { if (priorityQueue.size() \u0026lt; k) { priorityQueue.offer(i); } else if (priorityQueue.peek() \u0026lt; i) { priorityQueue.poll(); priorityQueue.offer(i); } } int[] result = new int[k]; for (int i = 0; i \u0026lt; k; i++) { result[i] = priorityQueue.poll(); } return result; } PriorityQueue 默认是自然顺序排序，如果要选择最大的 k 个数，可以构造小顶堆，每次取数组中剩余数与堆顶的元素进行比较，如果新数比堆顶元素大，则删除堆顶元素，并添加这个新数到堆中\nMap Collection 和 Map 组成了 java 的集合框架体系，Map 可以说是 java 中最高频使用的一种数据结构了，下面就来一起看看 Map 的神奇之处\nHashMap HashMap 是 java 中哈希表的实现，也算是最常用的 Map 实现了，由于 HashMap 的实现还算复杂，所以分多个子标题进行解析（ HashMap 的实现有很多精妙之处，其源码是值得阅读和推敲的，但是应试般的记忆和机械式的面试提问，算了不提也罢 - -）\n从成员变量开始 先从类定义的一些成员变量开始吧：\n1 2 3 4 5 6 7 8 9 10 11 static final int DEFAULT_INITIAL_CAPACITY = 1 \u0026lt;\u0026lt; 4; // aka 16 static final int MAXIMUM_CAPACITY = 1 \u0026lt;\u0026lt; 30; static final float DEFAULT_LOAD_FACTOR = 0.75f; static final int TREEIFY_THRESHOLD = 8; static final int UNTREEIFY_THRESHOLD = 6; static final int MIN_TREEIFY_CAPACITY = 64; DEFAULT_INITIAL_CAPACITY 是 1 左移 4 位其实就是 16 ，是 HashMap 默认的初始容量\nMAXIMUM_CAPACITY 是 HashMap 的最大容量\nDEFAULT_LOAD_FACTOR 为 0.75 ，是 HashMap 的装载因子，可以理解为 HashMap 初始容量为 16 ，那么 16 * 0.75 = 12 ，也就是当插入第 13 个元素时，HashMap 就会先进行扩容操作\nTREEIFY_THRESHOLD 是树化的阈值，HashMap 是由数组、链表、红黑树构成的（ HashMap 作为键值存储，实际上是一个数组，根据哈希算法对 key 进行计算得到应该存放的数组的索引位置，这必然导致哈希冲突，即数组的一个位置将存放多个元素，这些元素将以链表/红黑树的形式放入数组的某个位置上，其实只要将头节点/根节点放入数组对应的位置上），同一个数组槽位存在多个元素时，这些元素会先以链表的形式挂载在数组的对应槽位上，但是当链表的长度增长到一定程度时，也就是超过 8 时，就会进行树化，转换为红黑树重新挂载到对应的数组槽位（后面会详细讲解，这里只是提一下这个成员变量的含义）\nUNTREEIFY_THRESHOLD 是树退化的阈值，也就是红黑树的节点数小于 6 时重新转换为链表\nMIN_TREEIFY_CAPACITY 是树化时容量的最小阈值，也就是说光同一个槽位的元素超过 8 并不是一定会进行树化操作的，必须同时满足整个 HashMap 的容量等于或者超过 64 才行\n构造函数 HashMap 的构造函数有个很有意思的地方：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted } public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity \u0026lt; 0) throw new IllegalArgumentException(\u0026#34;Illegal initial capacity: \u0026#34; + initialCapacity); if (initialCapacity \u0026gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor \u0026lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\u0026#34;Illegal load factor: \u0026#34; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); } 注意这个指定容量的构造函数 HashMap(int initialCapacity) ，其直接调用了 HashMap(int initialCapacity, float loadFactor) 方法，在这个方法中有个奇怪的方法：tableSizeFor\n1 2 3 4 static final int tableSizeFor(int cap) { int n = -1 \u0026gt;\u0026gt;\u0026gt; Integer.numberOfLeadingZeros(cap - 1); return (n \u0026lt; 0) ? 1 : (n \u0026gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } 其中，Integer.numberOfLeadingZeros 方法，用来返回指定 int（\u0026gt;= 0） 以二进制形式展示时，从高位到低位碰到第一个 1 之前有多少个 0 ，举个简单的例子，比如 15 ，以二进制展示为：\n0000 0000 0000 0000 0000 0000 0000 1111\n15 - 1 就是：\n0000 0000 0000 0000 0000 0000 0000 1110\n那么在第一个 1 之前一共有 28 个 0 ，所以返回 28\n那么得到这个数有什么用呢？可以看到是将 -1 逻辑右移了这个返回值的位数，-1 的二进制补码为：\n1111 1111 1111 1111 1111 1111 1111 1111\n以 16 为例，右移 28 位就变成了：\n0000 0000 0000 0000 0000 0000 0000 1111\n最后再将这个数 + 1 ，得到：\n0000 0000 0000 0000 0000 0000 0001 0000\n也就是 16 ，也就是说这个方法是用来将用户设置的不规范（非 2 的整数次幂）的初始容量重新设置为 2 的整数次幂的（设置的值大于用户指定的值，且是最接近用户指定值的 2 的整数次幂值），至于为什么一定要将初始容量设置为 2 的整数次幂，后面会详细说到\n从添加元素说起 HashMap 比较核心的方法就是 put 方法了：\n1 2 3 public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } 在调用 putVal 方法之前，先是调用 hash 方法获取 key 的 hash 值，hash 方法如下：\n1 2 3 4 static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16); } 这个就是 HashMap 获取 hash 的函数，首先取得 key 的 hash 值，然后将其逻辑右移 16 位，再将结果和原哈希值进行逻辑与操作，其实就是将 key 的 hash 值的高 16 位向下扩散，降低一些特定数及小容量时 hash 碰撞的可能性，有的地方称之为振荡函数，下面是 java 官方的注释解释：\n计算 key.hashCode() 并将哈希的高位数扩展到低位数。因为哈希表使用了 2 的幂掩码，所以在当前掩码之上只变化几比特的哈希集总是会发生冲突（其中一个已知的例子是在小表格中保存连续整数的 Float 键集）。因此，我们应用一个变换，将高比特的影响向下扩散。比特传播的速度、效用和质量之间存在权衡。由于许多常见的哈希集已经合理分布（因此不会从扩展中受益），并且由于我们使用树来处理箱中的大型碰撞集，因此我们只是以最简单的方式对一些移位的位进行异或，以减少系统损失，并合并最高位的影响，否则由于哈希表边界的原因，这些位在索引计算中永远不会使用\n下面是 putVal 方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) \u0026amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node\u0026lt;K,V\u0026gt; e; K k; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode\u0026lt;K,V\u0026gt;)p).putTreeVal(this, tab, hash, key, value); else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size \u0026gt; threshold) resize(); afterNodeInsertion(evict); return null; } 懒初始化 putVal 方法很复杂，我们一段一段的来看，首先看看第一个 if 子句，即决定是否需要进行初始化操作：\n1 2 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; 首先判断 table 是否为空，这个判断就是检查 HashMap 有没有进行过初始化，首次插入元素时，table 肯定是 null 的，所以会进入 resize 方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 final Node\u0026lt;K,V\u0026gt;[] resize() { Node\u0026lt;K,V\u0026gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // ... else if (oldThr \u0026gt; 0) // initial capacity was placed in threshold newCap = oldThr; // ... if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({\u0026#34;rawtypes\u0026#34;,\u0026#34;unchecked\u0026#34;}) Node\u0026lt;K,V\u0026gt;[] newTab = (Node\u0026lt;K,V\u0026gt;[])new Node[newCap]; table = newTab; // ... return newTab; } resize 方法实际是用来扩容的，这里省略了大量的和初始化不相关的代码，只关注初始化的逻辑。可以看到就是设置 newCap 为 threshold （还记得之前构造函数的 tableSizeFor 方法吗，最后就是将 2 的整数次幂赋值给了 threshold），然后重新计算 threshold 为 newCap * loadFactor ，最后 new Node[] 并返回。需要注意的是，threshold 这个变量是表示下一次扩容的阈值，并不是容量，只是在构造函数中临时将容量保存在 threshold 中\n获取存储位置 确定了容量 n 之后，就可以来确认要插入元素的位置了，代码就是上面提到的\n1 2 if ((p = tab[i = (n - 1) \u0026amp; hash]) == null) tab[i] = newNode(hash, key, value, null); 可以看到，主要就是根据 (n - 1) \u0026amp; hash 来确定元素存储的位置的，这是个很有意思的方法，也是前面提到的为什么 HashMap 会将用户不规范的初始容量设定为 2 的整数次方幂的原因\n不妨想一想，2 的整数次方幂减去 1 之后用二进制表示是什么样的？我们以 16 为例，16 的二进制形式如下：\n0000 0000 0000 0000 0000 0000 0001 0000\n减去 1 以后如下：\n0000 0000 0000 0000 0000 0000 0000 1111\n没错，减去 1 以后，一定是低位全是 1 的形式，此时 \u0026amp; 上 hash 值，正好可以将 hash 值的地位全部保留下来，也就是余数，也是元素在 HashMap 数组中应该存储的位置\n哈希碰撞 我们知道，同一个对象的 hash 值一定是一样的，但是不同对象的 hash 值却是可能一样的。因为以 Java 为例，存储 hash 值的类型为 int 类型，总共就 32 位，而对象却可能是无穷无尽的，无尽的对象计算为一个有限的 32 位整数，遇到 hash 一致的情况是迟早的事。hash 值一致，那么经过容量对 hash 取模之后，得到的存储位置也就是一致的，此时元素该如何存储呢？这就是哈希碰撞\n解决哈希碰撞的方法有很多，常用的比如：\n开放寻址法 链地址法 再哈希法 建立公共溢出区 Java 的 HashMap 采用的方法是链地址法，也就是将碰撞的元素以链表的形式串联起来，然后将链表的头节点放入 hash 数组的指定位置。代码就是之前添加元素的后半段：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 Node\u0026lt;K,V\u0026gt; e; K k; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode\u0026lt;K,V\u0026gt;)p).putTreeVal(this, tab, hash, key, value); else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } 首先判断数组中元素的 hash 值是不是和要插入元素的 hash 值一致，如果一致，再用 equal 方法判断两个元素是不是相同，相同的话其实什么也不用做，只是 e = p ，后面会将数组中的元素替换为要插入的元素 如果上一个条件不符合，接着判断要插入位置中已存在的节点是不是树形节点，如果是树形节点就调用 TreeNode 的 putTreeVal 方法，对元素进行替换或插入，这里不阐述 TreeNode 的具体实现，只要知道其是一颗红黑树即可，感兴趣可以自行翻开源码和红黑树原理 最后一种情况就是链表，用一个 for 循环对链表进行遍历，遍历过程中不断的使用 hash 值 和 equals 方法判断是否存在元素一致的情况，如果一致就直接替换，不一致会一直遍历到链表尾部，然后进行尾插 头插还是尾插的问题 在解决哈希碰撞的过程中，HashMap 使用链表尾插的方式，为什么是尾插而不是头插呢？因为头插在多线程的情况下会产生循环链表的问题（其实 HashMap 本来就不是线程安全的，多线程情况下本来就不应该直接使用 HashMap），感兴趣的可以自行搜索\n删除元素和查找元素 删除元素 删除元素的源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 public V remove(Object key) { Node\u0026lt;K,V\u0026gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; } final Node\u0026lt;K,V\u0026gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, index; if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (p = tab[index = (n - 1) \u0026amp; hash]) != null) { Node\u0026lt;K,V\u0026gt; node = null, e; K k; V v; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) node = p; else if ((e = p.next) != null) { if (p instanceof TreeNode) node = ((TreeNode\u0026lt;K,V\u0026gt;)p).getTreeNode(hash, key); else { do { if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } if (node != null \u0026amp;\u0026amp; (!matchValue || (v = node.value) == value || (value != null \u0026amp;\u0026amp; value.equals(v)))) { if (node instanceof TreeNode) ((TreeNode\u0026lt;K,V\u0026gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; } } return null; } 代码整体不难理解，就是使用 (n - 1) \u0026amp; hash 得到元素所在位置，然后以次判断\n如果数组对应位置的元素 hash 值和要删除元素的 hash 值一致，并且两个元素使用 equals 方法判断相同，那么直接使 node = p ，后续判断到 node = p 后，会直接调用 tab[index] = node.next ，即将之前元素的下一个节点放入数组中（下一个节点为 null 也没有关系，就直接将 null 放入数组即可） 如果数组中存储的节点是一个树形节点，就使用 TreeNode 的 getTreeNode 方法找到对应的节点，并在后续使用 removeTreeNode 方法对节点进行删除，这里不做具体阐述 最后，如果是链表结构，那么就是用 do while 循环遍历链表，遍历过程中不断的比较 hash 值并使用 equals 方法判断是否相同，并在后续使用 p.next = node.next 将前一节点的后驱指针指向找到节点的下一个节点，以此来删除索引节点 查找元素 查找元素的过程其实和删除元素是极为相似的，核心就是使用 (n - 1) \u0026amp; hash 和 equals 方法，找到存储位置，并对数据结构进行遍历查找然后返回\nHashMap 是 Java 应用中最常用的数据结构之一了，参考 HashMap 的源码，我们可以发现很多精巧的设计，比如容量设置为 2 的整数次方幂、震荡函数、与运算代替取模运算、哈希碰撞等等\nCover from eberhardgross on unsplash\n","date":"2023-07-18T00:00:00Z","image":"https://yameizitd.github.io/p/java-%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/cover_hu3d03a01dcc18bc5be0e67db3d8d209a6_292617_120x120_fill_q75_box_smart1.jpg","permalink":"https://yameizitd.github.io/p/java-%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/","title":"Java 集合框架"}]